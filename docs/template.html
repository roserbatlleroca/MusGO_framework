<!DOCTYPE html>

<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>MusGO Framework: Assessing Opennesss in Music-Generative AI</title>
<link href="styles.css" rel="stylesheet"/>
<!--<link href="favicon.png" rel="icon" type="image/x-icon"/>-->
<script data-domain="roserbatlleroca.github.io/MusGO_framework/" defer="" src="https://plausible.io/js/script.js"></script>
</head>
<body>
<div id="header">
<h1><a href="" title="MusGO Framework: Assessing Opennesss in Music-Generative AI">MusGO Framework:</a> Assessing Opennesss in Music-Generative AI</h1><!--<img alt="Opening up ChatGPT" id="title-logo" src="logos/openchatgpt-logo-favicon-red-on-transparent.png"/>Opening up ChatGPT</a>: tracking openness of instruction-tuned LLMs</h1>--> 
</div>
<div id="content">
	<!--<p class="highlight" id="citation">‚ö°<strong>FAccT'24 paper</strong>‚ö° Liesenfeld, Andreas, and Mark Dingemanse. 2024. ‚ÄòRethinking Open Source Generative AI: Open-Washing and the EU AI Act‚Äô. In <em>The 2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT ‚Äô24)</em>. Rio de Janeiro, Brazil: ACM. (<a href="https://pure.mpg.de/pubman/item/item_3588217_2/component/file_3588218/liesenfeld_dingemanse_2024_FAccT_generative_AI_open-washing_EU_AI_Act.pdf" target="_blank">PDF</a>).</p>-->
	<p class="highlight" id="description">Introducing the <strong>MusGO Framework</strong>: A community-driven framework for assessing openness in music-generative AI.</p>
	<!--<p id="tagline">There is a growing amount of instruction-tuned text generators billing themselves as 'open source'. How open are they really? <span class="link-icon">üîó</span><a href="https://dl.acm.org/doi/10.1145/3630106.3659005" target="_blank">FAccT'24</a> <span class="link-icon">üîó</span><a href="https://doi.org/10.1145/3571884.3604316" target="_blank">CUI'23</a> <span class="link-icon">üîó</span><a href="https://github.com/opening-up-chatgpt/opening-up-chatgpt.github.io/">repo</a></p>-->
	<p id="tagline">With the notable rise of generative models in the music domain, we pose the question: how open are they? MusGO is built and applied to assess openness in music-generative models. Note that this site is part of the submission <em>'MusGO: A Community-Driven Framework for Asssessing Openness in Music-Generative AI'</em> at ACM Conference on Fairness, Accountability, and Transparency (FAccT '25), which is currently under review.</p>
	
	<h3>Openness assessment</h3>
		<div id="included-table"></div>

<p id="table-guide"><em>How to interpret this table?</em> MusGO framework is composed of 13 different dimensions of openness. It distinguishes between <em>essential</em> (1-8) and <em>nice-to-have</em> (9-13) categories. 
	Essential categories follow a three-level scale: (<span class="openness open"><strong>‚úîÔ∏é</strong> open</span>, <span class="openness partial"><strong>~</strong> partial</span> or <span class="openness closed"><strong>‚úò</strong> closed</span>). <!-- with a direct link to the available evidence; on hover, the cell will display the notes we have on file for that judgement. The name of each project is a direct link to source data.-->
	Instrad, nice-to-have categories are binary: whether that element exists (&#11088;) or not. The openness level is computed with the essential categories punctuations, where <strong>‚úîÔ∏é</strong> is 1, <strong>~</strong> is 0.5 and <strong>‚úò</strong> is 0 points. Openness level is normalised to obtained a value on a 100 point scale. 
	Models are arranged in descending order of openness level, placing the <strong>most open model</strong> first.</p>



	
<h4>Acknowledgments</h4>
<p>This site is an adapted version of <a href="https://opening-up-chatgpt.github.io/">https://opening-up-chatgpt.github.io/</a>.
 We are deeply grateful to the original creators, Andreas Liesenfeld, Alianda Lopez, and Mark Dingemanse, for their groundbreaking work on openness, transparency, and accountability in generative AI, which has inspired and shaped this project.</p>
 <p>
    For more details, please refer to their papers:
  </p>
  <ul>
    <li>
      Liesenfeld, Andreas, Alianda Lopez, and Mark Dingemanse. 2023. 
      <em>‚ÄúOpening up ChatGPT: Tracking Openness, Transparency, and Accountability in Instruction-Tuned Text Generators.‚Äù</em> 
      In <em>CUI '23: Proceedings of the 5th International Conference on Conversational User Interfaces</em>, July 19-21, Eindhoven. 
      DOI: <a href="https://doi.org/10.1145/3571884.3604316" target="_blank">10.1145/3571884.3604316</a>.
    </li>
    <li>
      Andreas Liesenfeld and Mark Dingemanse. 2024. 
      <em>‚ÄúRethinking open source generative AI: open washing and the EU AI Act.‚Äù</em> 
      In <em>The 2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT '24)</em>. 
      DOI: <a href="https://doi.org/10.1145/3630106.3659005" target="_blank">10.1145/3630106.3659005</a>.
    </li>
  </ul>
<!-- <h2>Why is openness important?</h2>
<p>Open research is the lifeblood of cumulative progress in science and engineering. Openness is key for fundamental research, for fostering critical computational literacy, and for making informed choices for or against deployment of instruction-tuned LLM architectures. The closed &amp; proprietary nature of ChatGPT and kin makes them fundamentally unfit for responsible use in research and education.</p>
<p>Open alternatives provide ways to build reproducible workflows, chart resource costs, and lessen reliance on corporate whims. One aim of our work here is to provide tools to track openness, transparency and accountability in the fast-evolving landscape of instruction-tuned text generators. Read more in the <a href="https://dl.acm.org/doi/10.1145/3571884.3604316" target="_blank">paper</a> (<a href="https://pure.mpg.de/pubman/item/item_3526897_1/component/file_3526898/Liesenfeld%20et%20al_2023_Opening%20up%20ChatGPT.pdf" target="_blank">PDF</a>) or <a href="https://github.com/opening-up-chatgpt/opening-up-chatgpt.github.io/" target="_blank">contribute to the repo</a>.</p>
<p class="highlight" id="contribute">If you know a model that should be listed here or a data point that needs updating, please see <a href="https://github.com/opening-up-chatgpt/">guidelines for contributors</a> and feel free to <a href="https://github.com/opening-up-chatgpt/opening-up-chatgpt.github.io/issues">open an issue or pull request</a> in our repository.</p>
<h2>TL;DR</h2>
<p>Our paper makes the following contributions:</p>
<ul>
<li>We review the risks of relying on proprietary software</li>
<li>We review best practices for open, transparent and accountable 'AI'</li>
<li>We find over 40 ChatGPT alternatives at varying degrees of openness, development and documentation</li>
<li>We argue that tech is never a <em>fait accompli</em> unless we make it so, and that openness enables critical computational literacy</li>
</ul>
<p>We find the following recurrent patterns:</p>
<ul>
<li>Many projects inherit data of dubious legality</li>
<li>Few projects share the all-important instruction-tuning</li>
<li>Preprints are rare, peer-reviewed papers even rarer</li>
<li>Synthetic instruction-tuning data is on the rise, with unknown consequences that are in need of research</li>
</ul>
<p>We conclude as follows:</p>
<blockquote id="conclusion">Openness is not the full solution to the scientific and ethical challenges of conversational text generators. Open data will not mitigate the harmful consequences of thoughtless deployment of large language models, nor the questionable copyright implications of scraping all publicly available data from the internet. However, openness does make original research possible, including efforts to build reproducible workflows and understand the fundamentals of instruction-tuned LLM architectures. Openness also enables checks and balances, fostering a culture of accountability for data and its curation, and for models and their deployment. We hope that our work provides a small step in this direction.
  </blockquote>

-->
<!-- 
<h2>Papers</h2>  
<p>Liesenfeld, Andreas, Alianda Lopez, and Mark Dingemanse. 2023. ‚ÄúOpening up ChatGPT: Tracking Openness, Transparency, and Accountability in Instruction-Tuned Text Generators.‚Äù In <em>CUI '23: Proceedings of the 5th International Conference on Conversational User Interfaces</em>. July 19-21, Eindhoven. doi: <a href="https://doi.org/10.1145/3571884.3604316" target="_blank">10.1145/3571884.3604316</a> (<a href="https://pure.mpg.de/pubman/item/item_3526897_1/component/file_3526898/Liesenfeld%20et%20al_2023_Opening%20up%20ChatGPT.pdf" target="_blank">PDF</a>).</p>

<p>Andreas Liesenfeld and Mark Dingemanse. 2024. Rethinking open source generative AI: open washing and the EU AI Act. In <em>The 2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT '24)</em>. Association for Computing Machinery, New York, NY, USA, 1774‚Äì1787. doi: <a href="https://doi.org/10.1145/3630106.3659005" target="_blank">10.1145/3630106.3659005</a></p>
-->
</div><!-- #content -->
<div id="footer">
<p>This site is an adapted version of <a href="https://opening-up-chatgpt.github.io/">https://opening-up-chatgpt.github.io/</a>.</p>
<p class="copyright">Website &amp; code ¬© 2025 by the authors.</p>
<p id="build-time"></p>
</div>
</body>
</html>
